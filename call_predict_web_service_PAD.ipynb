{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call Azure ML for PY Framework web service - Payroll Anomaly Detection\n",
    "\n",
    "###  http://b03d85f2-b070-497e-a0f8-03ec2315c0af.westus.azurecontainer.io/score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from ngamlfpy.utils import pulled_json_to_df, pulled_df_to_json\n",
    "from ngamlfpy.hrxmlconfig import MLModelConfig\n",
    "from ngamlfpy.pipeline import FileFinder\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "ml_service = 'PAD'\n",
    "num_emps_to_clip = 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_csv_input = True\n",
    "model_code =  'A001' \n",
    "model_version = '001' \n",
    "#input_file_name =  'TWV_SS01_010_EUH_SOL_SUS_BIWK_PP9_100_U3_201915_input.csv'\n",
    "input_file_name= 'PAD_A001_001_WDY_ALT_TST_ALTBM_WDT_000_sm_202003_input.csv'\n",
    "\n",
    "finder = FileFinder(ml_service, use_model_name_in=True, use_model_name_out=False, model_name=model_code, model_version = model_version,\n",
    "                         base_folder='./data', relative_input_folder=FileFinder.MLFOLDER_INPUT,\n",
    "                         relative_output_folder=FileFinder.MLFOLDER_PREDICT)\n",
    "\n",
    "full_path_in =  finder.get_full_input_file_name(input_file_name)  #os.path.join(args.data_folder, args.ml_service + '/input/' + args.model + '/' + args.model_version)\n",
    "\n",
    "#full_path_in = os.path.join(folder,args.input_file_name)\n",
    "\n",
    "\n",
    "df = pd.read_csv(full_path_in)\n",
    "#df = pd.read_csv('data/PAD/input/' + model_code + '/PAD_EUH_AKN_A05_ALL_EP5_984_N0_201908_input.csv')\n",
    "#df = pd.read_csv('data/PAD/input/M005/001/PAD_M005_001_EUH_ZZZ_Z10_MTHLY_EDF_310_ZZ_201905_input.csv')\n",
    "display(df.head())\n",
    "\n",
    "_,_,_,payroll_service, gcc, lcc, group, system, rest = finder.parse_input_file_name(input_file_name,include_remainder=True)\n",
    "client, abkrs, period, other = rest.split('_')\n",
    "ml_config = MLModelConfig.get_model_config_from_web_service_for_cust(ml_service, system=system,gcc=gcc,lcc=lcc,payroll_area=abkrs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_csv_file_as_json = True\n",
    "\n",
    "if use_csv_input:\n",
    "    print('Using csv input')\n",
    "    #j_predict = pulled_df_to_json(df,ml_config,'201902')\n",
    "    j_predict = pulled_df_to_json(df,ml_config,period,use_first_data_line_as_selection=True,use_value_title_format=True,clip_emps = num_emps_to_clip)\n",
    "\n",
    "    raw_data = {}\n",
    "    raw_data['data'] = j_predict\n",
    "\n",
    "    if save_csv_file_as_json:\n",
    "       predict_json_file_name =  input_file_name.split('.')[0] + '.json'\n",
    "       full_path_json = os.path.join(finder.get_output_folder(),predict_json_file_name)\n",
    "       print('Writing json predict in file: ', full_path_json)\n",
    "       with open(full_path_json, 'w') as outfile:\n",
    "           json.dump(raw_data, outfile, indent=4)\n",
    "           \n",
    "            \n",
    "else:        \n",
    "    import pprint\n",
    "    input_json_file_name = '' # <-- supply json file name here (including path)\n",
    "    print ('Using Json predict file: ',input_json_file_name)\n",
    "\n",
    "    with open(input_json_file_name) as json_data:\n",
    "            j_predict = json.load(json_data)\n",
    "\n",
    "print('Num emps: ',len(j_predict['values']))\n",
    "print('')\n",
    "print('First emp: ',j_predict['values'][0])\n",
    "print('')\n",
    "print('Selection: ',j_predict['selection'])\n",
    "print('')     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"Content-Type\":\"application/json\"}\n",
    "test_samples = json.dumps({'data':j_predict})\n",
    "test_samples = bytes(test_samples, encoding='utf8')        \n",
    "        \n",
    "print (json.dumps(j_predict['selection'], sort_keys=False, indent=4, separators=(',', ': ')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call Prediction Web Service\n",
    "\n",
    "### New  http://b03d85f2-b070-497e-a0f8-03ec2315c0af.westus.azurecontainer.io/score\n",
    "\n",
    "- Predict Tax amounts per emp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from ngamlfpy.utils import pulled_json_to_df, pulled_df_to_json\n",
    "from ngamlfpy.hrxmlconfig import MLModelConfig\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model_code =  'A001' #'M010'\n",
    "\n",
    "if model_code == 'M010':\n",
    "    model_version = '002'\n",
    "    ml_service = 'PAD'\n",
    "    payroll_service = 'EUH'\n",
    "    gcc = 'AKN'\n",
    "    lcc = 'A05'\n",
    "    variant = 'ALL'\n",
    "    system='EP5'\n",
    "    client = '984'\n",
    "    abkrs = 'N0'\n",
    "    period = '201908'\n",
    "elif model_code == 'M005':\n",
    "    model_version = '001'\n",
    "    ml_service = 'PAD'\n",
    "    payroll_service = 'EUH'\n",
    "    gcc = 'ZZZ'\n",
    "    lcc = 'Z10'\n",
    "    variant = 'MTHLY'\n",
    "    system='EDF'\n",
    "    client = '310'\n",
    "    abkrs = 'ZZ'\n",
    "    period = '201905'  \n",
    "elif model_code == 'A001':\n",
    "    model_version = '001'\n",
    "    ml_service = 'PAD'\n",
    "    payroll_service = 'WDY'\n",
    "    gcc = 'ALT'\n",
    "    lcc = 'TST'\n",
    "    variant = 'ALTBM'\n",
    "    system='WDT'\n",
    "    client = '000'\n",
    "    abkrs = 'sm'\n",
    "    period = '202003'        \n",
    "    \n",
    "use_csv_input = True\n",
    "\n",
    "save_csv_file_as_json = True\n",
    "\n",
    "input_csv_file_name = 'data/' + ml_service + '/input/' + model_code + '/' + model_version + '/'  + '_'.join([ml_service,model_code,model_version,payroll_service,gcc,lcc,variant,system,client,abkrs,period]) + '_input.csv'\n",
    "input_json_file_name = 'data/predict/' + model_code + '/' + model_code + '_test.json'\n",
    "print(input_csv_file_name)\n",
    "print(input_json_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert csv file to json to use for predictions  if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(input_csv_file_name)\n",
    "#df = pd.read_csv('data/PAD/input/' + model_code + '/PAD_EUH_AKN_A05_ALL_EP5_984_N0_201908_input.csv')\n",
    "#df = pd.read_csv('data/PAD/input/M005/001/PAD_M005_001_EUH_ZZZ_Z10_MTHLY_EDF_310_ZZ_201905_input.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_config = MLModelConfig.get_model_config_from_web_service_for_cust(ml_service, system=system,gcc=gcc,lcc=lcc,payroll_area=abkrs)\n",
    "#ml_config = MLModelConfig.get_model_config_from_web_service_for_cust('PAD', system='EP5',gcc='AKN',lcc='A05',payroll_area='N0')\n",
    "#ml_config = MLModelConfig.get_model_config_from_web_service_for_cust('PAD', system='EDF',gcc='ZZZ',lcc='Z10',payroll_area='ZZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_csv_input:\n",
    "    print('Using csv input')\n",
    "    j_predict = pulled_df_to_json(df,ml_config,period,use_first_data_line_as_selection=True,use_value_title_format=True)\n",
    "    \n",
    "    #Write json to disk for future use\n",
    "    #outJson = 'data/predict/M010/M010_test.json'\n",
    "    #outJson = 'data/predict/M005/M005_test.json'\n",
    "    outJson = input_json_file_name\n",
    "   \n",
    "    \n",
    "    if save_csv_file_as_json:\n",
    "        print ('Writing out json file: ',outJson)\n",
    "        with open(outJson, 'w') as outfile:\n",
    "            json.dump(j_predict, outfile,indent=4)\n",
    "            #json.dumps(json.loads(jTst), indent=4, sort_keys=True,outfile)\n",
    "        \n",
    "else:\n",
    "    import pprint\n",
    "\n",
    "    #model = 'M005'\n",
    "    #predict_file_folder = model_code\n",
    "    #predict_file_name = 'T001_test.json'\n",
    "    #predict_file_name = 'T001_test_actually_with_T003_emp_data.json'\n",
    "    #predict_file_name = 'T003_EQ1_402_ZCS_Z10_X3_201902_pulled.json'\n",
    "    #predict_file_name = 'T001_EQ1_402_ZCS_Z10_X1_201902_pulled.json'\n",
    "    #predict_file_name = model_code + '_test.json'\n",
    "    #data_dir='data/predict'\n",
    "    \n",
    "    predict_source = 'json'\n",
    "    #model_prefix = predict_file_folder \n",
    "    #predict_file_path = '/'.join([data_dir,model_prefix])\n",
    "    #full_predict_file_name = '/'.join([predict_file_path,predict_file_name])\n",
    "    \n",
    "    print ('Using Json predict file: ',input_json_file_name)\n",
    "\n",
    "    if predict_source == 'json':\n",
    "        with open(input_json_file_name) as json_data:\n",
    "            j_predict = json.load(json_data)\n",
    "\n",
    "    # j_data_vals_stripped = []  \n",
    "    # period = j_data['selection']['period']\n",
    "    # for val in j_data['values']:\n",
    "    #     if period == val['ForPeriod']:\n",
    "    #         j_data_vals_stripped.append(val)\n",
    "    # j_data['values']  = j_data_vals_stripped\n",
    "\n",
    "print('Num emps: ',len(j_predict['values']))\n",
    "print('')\n",
    "print('First emp: ',j_predict['values'][0])\n",
    "print('')\n",
    "print('Selection: ',j_predict['selection'])\n",
    "print('')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"Content-Type\":\"application/json\"}\n",
    "test_samples = json.dumps({'data':j_predict})\n",
    "test_samples = bytes(test_samples, encoding='utf8')        \n",
    "\n",
    "print (json.dumps(j_predict['selection'], sort_keys=False, indent=4, separators=(',', ': ')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call Prediction Web Service\n",
    "### Old - http://40.81.10.248:80/score\n",
    "### Not quite as oldhttp://89c0489d-f162-4cb2-8a62-d551fc60a36c.westus.azurecontainer.io/score\n",
    "### New  http://b03d85f2-b070-497e-a0f8-03ec2315c0af.westus.azurecontainer.io/score\n",
    "\n",
    "- Predict Tax amounts per emp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response = requests.post(\"http://b03d85f2-b070-497e-a0f8-03ec2315c0af.westus.azurecontainer.io/score\", test_samples, headers=headers)  #NGA_Tax_Withheld  Combined\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    json_predictions = response.json()\n",
    "    print('Prediction Web Service call successful - ' + str(len(json_predictions['Predictions'])) + ' emps processed' + ' Model used: ' + json_predictions['info']['azure_model_name'] + ' Model config ws status: ' + json_predictions['info']['config_web_service_call_status'])\n",
    "\n",
    "    print ('First 5 Tax predictions: ')\n",
    "    for pred in json_predictions['Predictions'][:5]:\n",
    "        print('   Anomaly Score: ' + str(pred))\n",
    "else:\n",
    "    print('web service failed. Status: ' + str(response.status_code) + ' message: ' +  str(response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_predictions['info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_predictions['selection']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [x['Score'] for x in json_predictions['Predictions']]\n",
    "scores = scores[:num_emps_to_clip]\n",
    "scores[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features = [x['Important_Features'] for x in json_predictions['Predictions']]\n",
    "important_features = important_features[:num_emps_to_clip]\n",
    "important_features[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clipped = df[:num_emps_to_clip].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clipped['Score'] = scores\n",
    "df_clipped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = pd.DataFrame(important_features,columns=['LF1','LF2','LF3'])\n",
    "df_clipped = df_clipped.join(df_features)\n",
    "df_clipped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clipped_sorted = df_clipped.sort_values(by=['Score'])\n",
    "df_clipped_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
