{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "# display the core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)\n",
    "\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.model import Model\n",
    "import os \n",
    "ws = Workspace.from_config(path='azure_config_dev.json')\n",
    "print(ws.name, ws.location, ws.resource_group, ws.location, sep='\\t')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_service = 'PAD'\n",
    "\n",
    "#TODO - replace with call to HRXML Config API to get algorithm details for web service\n",
    "if ml_service == 'TWV':\n",
    "    algorithm = 'DNN_MLPRegressor'\n",
    "    description = 'Tax Withholding Verification'\n",
    "elif ml_service == 'PAD':\n",
    "    algorithm = 'Isolation_Forest'\n",
    "    description = 'Payroll Anomaly detection'\n",
    "else:\n",
    "    algorithm = 'Other algorithm'\n",
    "    description = 'Other'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Choose published models to deploy in web service, and try  to download to ensure they exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#models_list =  [{'ml_service':'TWV','model_code':'SS01','model_version':'010','vers':1},{'ml_service':'TWV','model_code':'T001','model_version':'002','vers':1},{'ml_service':'PAD','model_code':'M010','model_version':'002','vers':1},{'ml_service':'PAD','model_code':'M005','model_version':'001','vers':1},{'ml_service':'PAD','model_code':'A001','model_version':'001','vers':5}] #,{'model_code':'T003','model_vers':2}]\n",
    "models_list =  [{'ml_service':'TWV','model_code':'T001','model_version':'002','vers':1},{'ml_service':'PAD','model_code':'M005','model_version':'001','vers':1}] #,{'model_code':'T003','model_vers':2}]\n",
    "#ml_service = 'TWV'\n",
    "\n",
    "\n",
    "twv_models = []\n",
    "\n",
    "for model_details in models_list:\n",
    "    ml_serv = model_details['ml_service']\n",
    "    model = model_details['model_code']  #'T003'\n",
    "    model_version = None\n",
    "    if 'model_version' in model_details:\n",
    "        model_version = model_details['model_version']\n",
    "    version = model_details['vers']\n",
    "    if model_version is None:\n",
    "        twv_model=Model(ws, ml_serv + '_model_' + model,version=version)\n",
    "    else:\n",
    "        twv_model=Model(ws, ml_serv + '_model_' + model + '_' + model_version,version=version)\n",
    "    twv_model.add_tags({'azure_model_vers':version})\n",
    "    twv_models.append(twv_model)\n",
    "\n",
    "    print('model: ' + str(twv_model.name) + ' ' + str(twv_model.version))\n",
    "\n",
    "    ser = twv_model.serialize()\n",
    "    print('ser: ' + str(ser))\n",
    "    twv_model.download(target_dir=os.path.join(os.getcwd(),'downloaded_models'), exist_ok=True)\n",
    "\n",
    "    # verify the downloaded model file\n",
    "    #file_path = os.path.join(os.getcwd(), \"sklearn_mnist_model.pkl\")\n",
    "\n",
    "    #os.stat(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "myenv = CondaDependencies()\n",
    "myenv.add_conda_package(\"scikit-learn\")\n",
    "myenv.add_conda_package(\"pandas\")\n",
    "myenv.add_conda_package(\"matplotlib\")\n",
    "myenv.add_conda_package(\"numpy\")\n",
    "myenv.add_conda_package(\"requests\")\n",
    "myenv.add_channel(\"conda-forge\")\n",
    "myenv.add_pip_package(\"azureml-pipeline-core\")\n",
    "\n",
    "with open(\"myenv.yml\",\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"myenv.yml\",\"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web service depoyment configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n",
    "                                               memory_gb=1, \n",
    "                                               tags={\"ml_service\": ml_service,\"algorithm\":algorithm}, \n",
    "                                               description=description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 1 - Use when updating an  existing web service with a new image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngamlfpy_package = 'ngamlfpy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_service = 'TWV' # for image purposes - has both pad and twv modesl in twvimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#rbm code to create new image\n",
    "\n",
    "from azureml.core.image import Image\n",
    "from azureml.core.image import ContainerImage\n",
    "\n",
    "new_img_name = 'mlfpyimage' #ml_service.lower() + 'image'\n",
    "image_config = ContainerImage.image_configuration(execution_script=\"predict_model.py\", \n",
    "                                                  runtime=\"python\", \n",
    "                                                  conda_file=\"myenv.yml\",\n",
    "                                                 dependencies=[os.path.join('.',ngamlfpy_package)\n",
    "                                                               #os.path.join('.', 'gen_utils.py'),\n",
    "                                                               #os.path.join('.', 'pipeline_utils.py'),\n",
    "                                                               #os.path.join('.',  'train_utils.py')\n",
    "                                                               ])\n",
    "\n",
    "\n",
    "img = Image.create(workspace=ws, name=new_img_name, models=twv_models, image_config=image_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rbm code to get webservice for existing image\n",
    "from azureml.core.webservice import Webservice\n",
    "\n",
    "#prev_image_name = 'twvdnn9' \n",
    "web_services = Webservice.list(workspace=ws, image_name=None, image_id=None, model_name=None, model_id=None, tags=None, properties=None)\n",
    "web_services\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_services[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=Image.list(workspace=ws)\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_img = images[0]\n",
    "new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rbm code to update existing webservie with new image\n",
    "web_services[0].update(image=new_img, tags=None, properties=None, description=ml_service + \" Prediction\", auth_enabled=None, ssl_enabled=None, ssl_cert_pem_file=None, ssl_key_pem_file=None, ssl_cname=None, enable_app_insights=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "web_services[0].get_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ... or Option 2) Use when deplying a new web service (also deploys new image at same time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.image import ContainerImage\n",
    "\n",
    "ngamlfpy_package = 'ngamlfpy'\n",
    "\n",
    "# configure the image\n",
    "image_config = ContainerImage.image_configuration(execution_script=\"predict_model.py\", \n",
    "                                                  runtime=\"python\", \n",
    "                                                  conda_file=\"myenv.yml\",\n",
    "                                                 dependencies=[\n",
    "                                                               os.path.join('.',ngamlfpy_package)\n",
    "                                                               #os.path.join('.', 'gen_utils.py'),\n",
    "                                                               #os.path.join('.', 'pipeline_utils.py'),\n",
    "                                                               #os.path.join('.',  'train_utils.py')\n",
    "                                                               ])\n",
    "\n",
    "service = Webservice.deploy_from_model(workspace=ws,\n",
    "                                       #name= ml_service.lower() + 'image',\n",
    "                                       name= 'mlfpyimage',\n",
    "                                       deployment_config=aciconfig,\n",
    "                                       models=twv_models,\n",
    "                                       image_config=image_config)\n",
    "\n",
    "\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: can debug prediction web service with service.get_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try running web service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_services[0].scoring_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "model = 'T001'\n",
    "predict_file_name =  model + '_test.json'\n",
    "data_dir='data/predict'\n",
    "predict_source = 'json'\n",
    "model_prefix = model\n",
    "predict_file_path = '/'.join([data_dir,model_prefix])\n",
    "full_predict_file_name = '/'.join([predict_file_path,predict_file_name])\n",
    "print ('Predict file: ',full_predict_file_name)\n",
    "if predict_source == 'json':\n",
    "    with open(full_predict_file_name) as json_data:\n",
    "        j_data = json.load(json_data)\n",
    "raw_data = {}\n",
    "raw_data['data'] = j_data\n",
    "raw_data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_str = json.dumps(raw_data)\n",
    "test_samples = bytes(raw_data_str, encoding='utf8')\n",
    "result = web_services[0].run(input_data=test_samples)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "\n",
    "# predict_file_name = model + '_test.json'\n",
    "# data_dir='data/predict'\n",
    "# predict_source = 'json'\n",
    "# model_prefix = model + '_' + target_vers\n",
    "# predict_file_path = '/'.join([data_dir,model_prefix])\n",
    "# full_predict_file_name = '/'.join([predict_file_path,predict_file_name])\n",
    "# print ('Predict file: ',full_predict_file_name)\n",
    "# if predict_source == 'json':\n",
    "#     with open(full_predict_file_name) as json_data:\n",
    "#         j_data = json.load(json_data)\n",
    "        \n",
    "\n",
    "# test_samples = json.dumps({\"data\": j_data})\n",
    "# test_samples = bytes(test_samples, encoding='utf8')\n",
    "\n",
    "# # predict using the deployed model\n",
    "# result = service.run(input_data=test_samples)\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
