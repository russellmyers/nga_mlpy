{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "from azureml.core import Experiment\n",
    "\n",
    "# check core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ml service / model to be trained\n",
    "model_name =  'A001'#'T001' #'SS01' #'M010'#'M005' #\"T001\" #\"SS01\"\n",
    "ml_service = 'PAD' # 'TWV' #'PAD' #\"TWV\"\n",
    "model_version = '001' # '002' #'010' #'002' #\"001\" #\"009\" # None for latest - although currently None doesn't seem to work on Azure\n",
    "\n",
    "#Hyperparameters for neural network\n",
    "learning_rate =  0.001\n",
    "iters = 2000\n",
    "hidden_layers = [100,100]\n",
    "regularization = 1.0\n",
    "#Hyperparameters for isolation forest\n",
    "iso_num_estimators = 200\n",
    "iso_max_samples = 'auto'\n",
    "iso_max_features = '1.0'\n",
    "\n",
    "\n",
    "#Experiment\n",
    "experiment_name = \"train_\" + ml_service + '_' + model_name + '_' + model_version\n",
    "print('Experiment name: ',experiment_name)\n",
    "\n",
    "#Script locations\n",
    "relative_script_folder = 'azure_upload_scripts'\n",
    "training_script_file_name = 'train_model.py'\n",
    "ngamlfpy_package_name = 'ngamlfpy'\n",
    "\n",
    "#other\n",
    "required_conda_packages = ['scikit-learn','pandas','matplotlib','numpy']\n",
    "data_folder = './data'\n",
    "workspace_config_file = 'azure_config_dev.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create workspace, experiment, datastore objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load workspace configuration from the config.json file in the current folder.\n",
    "ws = Workspace.from_config(path=workspace_config_file)\n",
    "print(ws.name, ws.location, ws.resource_group, ws.location, sep='\\t')\n",
    "\n",
    "exp = Experiment(workspace=ws, name=experiment_name)\n",
    "print(exp.name)\n",
    "\n",
    "ds = ws.get_default_datastore()\n",
    "print(ds.datastore_type, ds.account_name, ds.container_name)\n",
    "print(ds.path(data_folder).as_mount())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get (or create)  compute target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "import os\n",
    "\n",
    "# choose a name for your cluster\n",
    "compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"cpucluster\") #cpucluster #\"aml-compute\" # \"try-gpu\"\n",
    "compute_min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 1) #1 to get ready machine\n",
    "compute_max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 4)\n",
    "\n",
    "# This example uses CPU VM. For using GPU VM, set SKU to STANDARD_NC6\n",
    "vm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_SKU\", \"STANDARD_D2_V2\") #\"STANDARD_NC6\")#\"STANDARD_D2_V2\")\n",
    "\n",
    "\n",
    "if compute_name in ws.compute_targets:\n",
    "    compute_target = ws.compute_targets[compute_name]\n",
    "    if compute_target and type(compute_target) is AmlCompute:\n",
    "        print('found compute target. just use it. ' + compute_name)\n",
    "else:\n",
    "    print('creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = vm_size,\n",
    "                                                                min_nodes = compute_min_nodes, \n",
    "                                                                max_nodes = compute_max_nodes)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n",
    "    \n",
    "    # can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it will use the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    \n",
    "     # For a more detailed view of current AmlCompute status, use get_status()\n",
    "    print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#script folder\n",
    "import os\n",
    "script_folder = os.path.join(os.getcwd(), relative_script_folder)\n",
    "os.makedirs(script_folder, exist_ok=True)\n",
    "import shutil\n",
    "\n",
    "\n",
    "from distutils.dir_util import copy_tree\n",
    "files_in_ngamlfpy_copied = copy_tree(ngamlfpy_package_name, os.path.join(script_folder,ngamlfpy_package_name))\n",
    "\n",
    "print('Files in package ',ngamlfpy_package_name,' copied: ')\n",
    "for file_copied in files_in_ngamlfpy_copied:\n",
    "    print('  ',file_copied)\n",
    "\n",
    "print(' ')    \n",
    "print('Script copied: ')    \n",
    "shutil.copy(training_script_file_name,script_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = model_name\n",
    "\n",
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "script_params = {\n",
    "    '--data-folder': ds.path(data_folder).as_mount(),\n",
    "    \n",
    "    #only relevant for neural network based ml services:\n",
    "    '--learning-rate' : learning_rate,\n",
    "    '--iters'         : iters,\n",
    "    '--hidden-layers' : hidden_layers,\n",
    "    '--regularization': regularization,\n",
    "   #only relevant for isolation forest based ml services: \n",
    "    '--iso-num-estimators': iso_num_estimators,\n",
    "    '--iso-max-samples': iso_max_samples,\n",
    "    '--iso-max-features': iso_max_features,\n",
    "\n",
    "    '--model'         : model,\n",
    "    '--ml_service'    : ml_service,\n",
    "    '--model-version' : model_version\n",
    "    \n",
    "}\n",
    "\n",
    "est = Estimator(source_directory=script_folder,\n",
    "                script_params=script_params,\n",
    "                compute_target=compute_target,\n",
    "                entry_script=training_script_file_name,\n",
    "                conda_packages=required_conda_packages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit training run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = exp.submit(config=est)\n",
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor training run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify show_output to True for a verbose log\n",
    "run.wait_for_completion(show_output=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register Model if training run is sufficiently successful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get metrics and prepare tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(run.get_metrics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_num = 6  # Need to manually set run num, as isn't shown in metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from ngamlfpy.hrxmlconfig import MLModelConfig\n",
    "metrics = run.get_metrics()\n",
    "dets = run.get_details()\n",
    "\n",
    "#TODO - replace with call to HRXML Config API to get algorithm details for web service\n",
    "if ml_service == 'TWV':\n",
    "    algorithm = 'DNN_MLPRegressor'\n",
    "    description = 'Tax Withholding Verification'\n",
    "elif ml_service == 'PAD':\n",
    "    algorithm = 'Isolation_Forest'\n",
    "    description = 'Payroll Anomaly detection'\n",
    "else:\n",
    "    algorithm = 'Other algorithm'\n",
    "    description = 'Other'\n",
    "    \n",
    "tags = {'RunNumber':run_num,'RunId':dets['runId'],'Model':metrics['Model Name'],'ModelVersion':model_version,'TrainSetSize':metrics['num train examples'],'Algorithm':algorithm,'AlgorithmType':metrics['algorithm']}\n",
    "\n",
    "if algorithm == 'Isolation_Forest':\n",
    "    tags['ISONumEstimators'] = metrics['iso num estimators']\n",
    "    tags['ISOMaxSamples'] = metrics['iso max samples']\n",
    "    tags['ISOMaxFeatures'] = metrics['iso max features']\n",
    "else:\n",
    "    tags['HiddenLayers'] = metrics['num hidden layers']\n",
    "    tags['LearningRate'] = metrics['learning rate']\n",
    "    tags['Iters'] = metrics['iters']         \n",
    "\n",
    "model_config = MLModelConfig.get_model_config_from_web_service_for_model(ml_service,model)\n",
    "\n",
    "if model_config:\n",
    "    cat_feats = len(model_config.get_feature_field_names_with_type('C'))\n",
    "    num_feats = len(model_config.get_feature_field_names_with_type('N'))\n",
    "    tags['NumFeatures'] = cat_feats + num_feats\n",
    "else:\n",
    "    tags['NumFeatures'] = 0\n",
    "tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register model \n",
    "\n",
    "azure_model_name = ml_service + '_model_' + model + '_' + model_version\n",
    "\n",
    "reg_model = run.register_model(model_name=azure_model_name, model_path='outputs/' + ml_service + '_model_' + model + '_' + model_version + '.pkl',tags=tags) #, description = description)\n",
    "print(reg_model.name, reg_model.id, reg_model.version, sep='\\t')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
