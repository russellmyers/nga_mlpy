{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run and monitor training experiment on Azure (and optionally publish trained model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version:  1.0.18\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "from azureml.core import Experiment\n",
    "\n",
    "# check core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ml service / model to be trained\n",
    "ml_service =   'TWV'  #'PAD' #\"TWV\"\n",
    "model_name =   'SS01' #'A001'#'T001' #'SS01' #'M010'#'M005' #\"T001\" #\"SS01\"\n",
    "model_version =  '011' # '001' # '002' #'010' #'002' #\"001\" #\"009\" # None for latest - although currently None doesn't seem to work on Azure\n",
    "clip_training_set = -1 # Dont clip\n",
    "clip_test_set = -1 # Dont clip\n",
    "\n",
    "#Hyperparameters for neural network\n",
    "learning_rate =  0.001\n",
    "iters = 2000\n",
    "hidden_layers = [100,100]\n",
    "regularization = 1.0\n",
    "\n",
    "#Hyperparameters for isolation forest\n",
    "iso_num_estimators = 200\n",
    "iso_max_samples = 'auto'\n",
    "iso_max_features = '1.0'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment name:  train_TWV_SS01_011\n"
     ]
    }
   ],
   "source": [
    "#Experiment\n",
    "experiment_name = \"train_\" + ml_service + '_' + model_name + '_' + model_version\n",
    "print('Experiment name: ',experiment_name)\n",
    "\n",
    "#Script locations\n",
    "relative_script_folder = 'azure_upload_scripts'\n",
    "training_script_file_name = 'train_model.py'\n",
    "ngamlfpy_package_name = 'ngamlfpy'\n",
    "\n",
    "#other\n",
    "required_conda_packages = ['scikit-learn','pandas','matplotlib','numpy']\n",
    "data_folder = './data'\n",
    "workspace_config_file = 'azure_config_dev.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create workspace, experiment, datastore objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: C:\\Users\\russellM\\OneDrive - Northgate Information Solutions Limited\\Documents\\GitLab\\AzureML\\nga_mlpy\\azure_config_dev.json\n",
      "twv_test-ws\taustraliaeast\tPOCML\taustraliaeast\n",
      "train_TWV_SS01_011\n",
      "AzureBlob twvtestws9297627118 azureml-blobstore-bb811392-f07a-47a4-8d37-dd1a5a5aa90f\n",
      "$AZUREML_DATAREFERENCE_7b308a6f2fa34c12842062a665d853fc\n"
     ]
    }
   ],
   "source": [
    "# load workspace configuration from the config.json file in the current folder.\n",
    "ws = Workspace.from_config(path=workspace_config_file)\n",
    "print(ws.name, ws.location, ws.resource_group, ws.location, sep='\\t')\n",
    "\n",
    "exp = Experiment(workspace=ws, name=experiment_name)\n",
    "print(exp.name)\n",
    "\n",
    "ds = ws.get_default_datastore()\n",
    "print(ds.datastore_type, ds.account_name, ds.container_name)\n",
    "print(ds.path(data_folder).as_mount())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get (or create)  compute target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found compute target. just use it. cpucluster\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "import os\n",
    "\n",
    "# choose a name for your cluster\n",
    "compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"cpucluster\") #cpucluster #\"aml-compute\" # \"try-gpu\"\n",
    "compute_min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 1) #1 to get ready machine\n",
    "compute_max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 4)\n",
    "\n",
    "# This example uses CPU VM. For using GPU VM, set SKU to STANDARD_NC6\n",
    "vm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_SKU\", \"STANDARD_D2_V2\") #\"STANDARD_NC6\")#\"STANDARD_D2_V2\")\n",
    "\n",
    "\n",
    "if compute_name in ws.compute_targets:\n",
    "    compute_target = ws.compute_targets[compute_name]\n",
    "    if compute_target and type(compute_target) is AmlCompute:\n",
    "        print('found compute target. just use it. ' + compute_name)\n",
    "else:\n",
    "    print('creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = vm_size,\n",
    "                                                                min_nodes = compute_min_nodes, \n",
    "                                                                max_nodes = compute_max_nodes)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n",
    "    \n",
    "    # can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it will use the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    \n",
    "     # For a more detailed view of current AmlCompute status, use get_status()\n",
    "    print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in package  ngamlfpy  copied: \n",
      "   C:\\Users\\russellM\\OneDrive - Northgate Information Solutions Limited\\Documents\\GitLab\\AzureML\\nga_mlpy\\azure_upload_scripts\\ngamlfpy\\algorithms.py\n",
      "   C:\\Users\\russellM\\OneDrive - Northgate Information Solutions Limited\\Documents\\GitLab\\AzureML\\nga_mlpy\\azure_upload_scripts\\ngamlfpy\\hrxmlconfig.py\n",
      "   C:\\Users\\russellM\\OneDrive - Northgate Information Solutions Limited\\Documents\\GitLab\\AzureML\\nga_mlpy\\azure_upload_scripts\\ngamlfpy\\outputs\\PAD_model_A001_001.pkl\n",
      "   C:\\Users\\russellM\\OneDrive - Northgate Information Solutions Limited\\Documents\\GitLab\\AzureML\\nga_mlpy\\azure_upload_scripts\\ngamlfpy\\pipeline.py\n",
      "   C:\\Users\\russellM\\OneDrive - Northgate Information Solutions Limited\\Documents\\GitLab\\AzureML\\nga_mlpy\\azure_upload_scripts\\ngamlfpy\\train.py\n",
      "   C:\\Users\\russellM\\OneDrive - Northgate Information Solutions Limited\\Documents\\GitLab\\AzureML\\nga_mlpy\\azure_upload_scripts\\ngamlfpy\\utils.py\n",
      "   C:\\Users\\russellM\\OneDrive - Northgate Information Solutions Limited\\Documents\\GitLab\\AzureML\\nga_mlpy\\azure_upload_scripts\\ngamlfpy\\__init__.py\n",
      "   C:\\Users\\russellM\\OneDrive - Northgate Information Solutions Limited\\Documents\\GitLab\\AzureML\\nga_mlpy\\azure_upload_scripts\\ngamlfpy\\__pycache__\\algorithms.cpython-37.pyc\n",
      "   C:\\Users\\russellM\\OneDrive - Northgate Information Solutions Limited\\Documents\\GitLab\\AzureML\\nga_mlpy\\azure_upload_scripts\\ngamlfpy\\__pycache__\\hrxmlconfig.cpython-36.pyc\n",
      "   C:\\Users\\russellM\\OneDrive - Northgate Information Solutions Limited\\Documents\\GitLab\\AzureML\\nga_mlpy\\azure_upload_scripts\\ngamlfpy\\__pycache__\\hrxmlconfig.cpython-37.pyc\n",
      "   C:\\Users\\russellM\\OneDrive - Northgate Information Solutions Limited\\Documents\\GitLab\\AzureML\\nga_mlpy\\azure_upload_scripts\\ngamlfpy\\__pycache__\\pipeline.cpython-36.pyc\n",
      "   C:\\Users\\russellM\\OneDrive - Northgate Information Solutions Limited\\Documents\\GitLab\\AzureML\\nga_mlpy\\azure_upload_scripts\\ngamlfpy\\__pycache__\\pipeline.cpython-37.pyc\n",
      "   C:\\Users\\russellM\\OneDrive - Northgate Information Solutions Limited\\Documents\\GitLab\\AzureML\\nga_mlpy\\azure_upload_scripts\\ngamlfpy\\__pycache__\\train.cpython-37.pyc\n",
      "   C:\\Users\\russellM\\OneDrive - Northgate Information Solutions Limited\\Documents\\GitLab\\AzureML\\nga_mlpy\\azure_upload_scripts\\ngamlfpy\\__pycache__\\utils.cpython-36.pyc\n",
      "   C:\\Users\\russellM\\OneDrive - Northgate Information Solutions Limited\\Documents\\GitLab\\AzureML\\nga_mlpy\\azure_upload_scripts\\ngamlfpy\\__pycache__\\utils.cpython-37.pyc\n",
      "   C:\\Users\\russellM\\OneDrive - Northgate Information Solutions Limited\\Documents\\GitLab\\AzureML\\nga_mlpy\\azure_upload_scripts\\ngamlfpy\\__pycache__\\__init__.cpython-36.pyc\n",
      "   C:\\Users\\russellM\\OneDrive - Northgate Information Solutions Limited\\Documents\\GitLab\\AzureML\\nga_mlpy\\azure_upload_scripts\\ngamlfpy\\__pycache__\\__init__.cpython-37.pyc\n",
      " \n",
      "Script copied: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\russellM\\\\OneDrive - Northgate Information Solutions Limited\\\\Documents\\\\GitLab\\\\AzureML\\\\nga_mlpy\\\\azure_upload_scripts\\\\train_model.py'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#script folder\n",
    "import os\n",
    "script_folder = os.path.join(os.getcwd(), relative_script_folder)\n",
    "os.makedirs(script_folder, exist_ok=True)\n",
    "import shutil\n",
    "\n",
    "\n",
    "from distutils.dir_util import copy_tree\n",
    "files_in_ngamlfpy_copied = copy_tree(ngamlfpy_package_name, os.path.join(script_folder,ngamlfpy_package_name))\n",
    "\n",
    "print('Files in package ',ngamlfpy_package_name,' copied: ')\n",
    "for file_copied in files_in_ngamlfpy_copied:\n",
    "    print('  ',file_copied)\n",
    "\n",
    "print(' ')    \n",
    "print('Script copied: ')    \n",
    "shutil.copy(training_script_file_name,script_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = model_name\n",
    "\n",
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "script_params = {\n",
    "    '--data-folder': ds.path(data_folder).as_mount(),\n",
    "    '--model'             : model,\n",
    "    '--ml_service'        : ml_service,\n",
    "    '--model-version'     : model_version,\n",
    "    '--clip_training_set' : clip_training_set,\n",
    "    '--clip_test_set'     : clip_test_set,\n",
    "    \n",
    "    #only relevant for neural network based ml services:\n",
    "    '--learning-rate' : learning_rate,\n",
    "    '--iters'         : iters,\n",
    "    '--hidden-layers' : hidden_layers,\n",
    "    '--regularization': regularization,\n",
    "   #only relevant for isolation forest based ml services: \n",
    "    '--iso-num-estimators': iso_num_estimators,\n",
    "    '--iso-max-samples': iso_max_samples,\n",
    "    '--iso-max-features': iso_max_features\n",
    "\n",
    " \n",
    "    \n",
    "}\n",
    "\n",
    "est = Estimator(source_directory=script_folder,\n",
    "                script_params=script_params,\n",
    "                compute_target=compute_target,\n",
    "                entry_script=training_script_file_name,\n",
    "                conda_packages=required_conda_packages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit training run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>train_TWV_SS01_011</td><td>train_TWV_SS01_011_1585884574_dd621b24</td><td>azureml.scriptrun</td><td>Starting</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/0c7f1ae6-7228-403f-ba54-84e72c46d6cf/resourceGroups/POCML/providers/Microsoft.MachineLearningServices/workspaces/twv_test-ws/experiments/train_TWV_SS01_011/runs/train_TWV_SS01_011_1585884574_dd621b24\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: train_TWV_SS01_011,\n",
       "Id: train_TWV_SS01_011_1585884574_dd621b24,\n",
       "Type: azureml.scriptrun,\n",
       "Status: Starting)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = exp.submit(config=est)\n",
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor training run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a825fa407854a59aaf4fd60058d4e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'runId': 'train_TWV_SS01_011_1585884574_dd621b24',\n",
       " 'target': 'cpucluster',\n",
       " 'status': 'Finalizing',\n",
       " 'startTimeUtc': '2020-04-03T03:30:13.473227Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'amlcompute',\n",
       "  'ContentSnapshotId': 'dcefdd29-374a-48dc-8ac4-1c1b87375727',\n",
       "  'AzureML.DerivedImageName': 'azureml/azureml_47c164f4b09750356d7cb5558152fe9b',\n",
       "  'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
       "  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n",
       " 'runDefinition': {'script': 'train_model.py',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--data-folder',\n",
       "   '$AZUREML_DATAREFERENCE_4a4a3ceda23643f88b19a6cbe8881371',\n",
       "   '--model',\n",
       "   'SS01',\n",
       "   '--ml_service',\n",
       "   'TWV',\n",
       "   '--model-version',\n",
       "   '011',\n",
       "   '--clip_training_set',\n",
       "   '-1',\n",
       "   '--clip_test_set',\n",
       "   '-1',\n",
       "   '--learning-rate',\n",
       "   '0.001',\n",
       "   '--iters',\n",
       "   '2000',\n",
       "   '--hidden-layers',\n",
       "   '100',\n",
       "   '100',\n",
       "   '--regularization',\n",
       "   '1.0',\n",
       "   '--iso-num-estimators',\n",
       "   '200',\n",
       "   '--iso-max-samples',\n",
       "   'auto',\n",
       "   '--iso-max-features',\n",
       "   '1.0'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'cpucluster',\n",
       "  'dataReferences': {'4a4a3ceda23643f88b19a6cbe8881371': {'dataStoreName': 'workspaceblobstore',\n",
       "    'mode': 'Mount',\n",
       "    'pathOnDataStore': './data',\n",
       "    'pathOnCompute': None,\n",
       "    'overwrite': False}},\n",
       "  'data': {},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 1,\n",
       "  'environment': {'name': 'Experiment train_TWV_SS01_011 Environment',\n",
       "   'version': 'Autosave_2020-04-03T03:19:38Z_5a9e8bf3',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults']},\n",
       "      'scikit-learn',\n",
       "      'pandas',\n",
       "      'matplotlib',\n",
       "      'numpy'],\n",
       "     'name': 'azureml_d8060b77b3f17a9a1ecb5c5b1fed4b78'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:0.2.3',\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': True,\n",
       "    'shmSize': '1g',\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': ['https://mmlspark.azureedge.net/maven'],\n",
       "    'packages': [{'group': 'com.microsoft.ml.spark',\n",
       "      'artifact': 'mmlspark_2.11',\n",
       "      'version': '0.12'}],\n",
       "    'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 1},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '1g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}}},\n",
       " 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_9c1ff52eaa52954942d4ce9899ead770fff201cadc2e108dcc99ef4539be2b48_d.txt': 'https://twvtestws9297627118.blob.core.windows.net/azureml/ExperimentRun/dcid.train_TWV_SS01_011_1585884574_dd621b24/azureml-logs/55_azureml-execution-tvmps_9c1ff52eaa52954942d4ce9899ead770fff201cadc2e108dcc99ef4539be2b48_d.txt?sv=2019-02-02&sr=b&sig=phyK1kr17dG%2BKy9IJJ8Bac5PXSd4DBt14Fjzu1fgS2s%3D&st=2020-04-03T03%3A21%3A56Z&se=2020-04-03T11%3A31%3A56Z&sp=r',\n",
       "  'azureml-logs/65_job_prep-tvmps_9c1ff52eaa52954942d4ce9899ead770fff201cadc2e108dcc99ef4539be2b48_d.txt': 'https://twvtestws9297627118.blob.core.windows.net/azureml/ExperimentRun/dcid.train_TWV_SS01_011_1585884574_dd621b24/azureml-logs/65_job_prep-tvmps_9c1ff52eaa52954942d4ce9899ead770fff201cadc2e108dcc99ef4539be2b48_d.txt?sv=2019-02-02&sr=b&sig=K2TWj%2Fe64Lr5Yky%2BPWLM1fyKetf3dHqM3M15%2BTIML88%3D&st=2020-04-03T03%3A21%3A56Z&se=2020-04-03T11%3A31%3A56Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://twvtestws9297627118.blob.core.windows.net/azureml/ExperimentRun/dcid.train_TWV_SS01_011_1585884574_dd621b24/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=4uQ%2FmF0Td%2FG5ZnAI2ATUn6RuMi3kVLpUlXYtfQLtVsY%3D&st=2020-04-03T03%3A21%3A56Z&se=2020-04-03T11%3A31%3A56Z&sp=r',\n",
       "  'azureml-logs/75_job_post-tvmps_9c1ff52eaa52954942d4ce9899ead770fff201cadc2e108dcc99ef4539be2b48_d.txt': 'https://twvtestws9297627118.blob.core.windows.net/azureml/ExperimentRun/dcid.train_TWV_SS01_011_1585884574_dd621b24/azureml-logs/75_job_post-tvmps_9c1ff52eaa52954942d4ce9899ead770fff201cadc2e108dcc99ef4539be2b48_d.txt?sv=2019-02-02&sr=b&sig=vzA3RgxmpkfKu1FB0T3za%2BwUCTgQl7%2B%2F1XwKH%2F7gWTo%3D&st=2020-04-03T03%3A21%3A56Z&se=2020-04-03T11%3A31%3A56Z&sp=r',\n",
       "  'azureml-logs/process_info.json': 'https://twvtestws9297627118.blob.core.windows.net/azureml/ExperimentRun/dcid.train_TWV_SS01_011_1585884574_dd621b24/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=VlnTAekwOQz2mag%2FMNTvgU6A2YIrlrD3NpSaHQ9wbps%3D&st=2020-04-03T03%3A21%3A56Z&se=2020-04-03T11%3A31%3A56Z&sp=r',\n",
       "  'azureml-logs/process_status.json': 'https://twvtestws9297627118.blob.core.windows.net/azureml/ExperimentRun/dcid.train_TWV_SS01_011_1585884574_dd621b24/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=6lSUHdPHK0OR%2BPpGu9jXXAJnIMhJvilw1AdUdH5tMh8%3D&st=2020-04-03T03%3A21%3A56Z&se=2020-04-03T11%3A31%3A56Z&sp=r'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify show_output to True for a verbose log\n",
    "run.wait_for_completion(show_output=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register Model if training run is sufficiently successful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get metrics and prepare tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ML Service': 'TWV', 'Model Name': 'SS01', 'Training start time': '2020-04-03 03:30:46.144930', 'regularization rate': 1.0, 'Acc train': 24.85256950294861, 'Acc test': 24.410774410774412, 'cost train': 4593.326608256108, 'cost test': 4024.1551505050493, 'iters': 2000, 'batch size': 200, 'learning rate': 0.001, 'num hidden layers': 2, 'iso num estimators': 200, 'iso max samples': 'auto', 'iso max features': 1.0, 'num train examples': 2374, 'algorithm': 'scikit_neural_network_regressor', 'training_code_version': '0.1d', 'Training end time': '2020-04-03 03:31:42.995088', 'Cost per iteration': None, 'Train set - Percentage diff per employee': None, 'Train set  abs perc differences (actual vs predicted Tax) per employee': None, 'Train set - Percentage diff per employee Histogram': None, 'Test set - Percentage diff per employee': None, 'Test set - Percentage differences': None, 'Train set - Percentage differences': None}\n"
     ]
    }
   ],
   "source": [
    "print(run.get_metrics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_num = 5  # Need to manually set run num, as isn't shown in metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "web service call successful:  api/customer-models \n",
      "web service call successful:  api/customer-models/6 \n",
      "web service call successful:  api/model-info ?ml_service=TWV&system=PP9&gcc=SOL&lcc=SUS&variant=BIWK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'RunNumber': 5,\n",
       " 'RunId': 'train_TWV_SS01_011_1585884574_dd621b24',\n",
       " 'Model': 'SS01',\n",
       " 'ModelVersion': '011',\n",
       " 'TrainSetSize': 2374,\n",
       " 'Algorithm': 'DNN_MLPRegressor',\n",
       " 'AlgorithmType': 'scikit_neural_network_regressor',\n",
       " 'HiddenLayers': 2,\n",
       " 'LearningRate': 0.001,\n",
       " 'Iters': 2000,\n",
       " 'NumFeatures': 20}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ngamlfpy.hrxmlconfig import MLModelConfig\n",
    "metrics = run.get_metrics()\n",
    "dets = run.get_details()\n",
    "\n",
    "#TODO - replace with call to HRXML Config API to get algorithm details for web service\n",
    "if ml_service == 'TWV':\n",
    "    algorithm = 'DNN_MLPRegressor'\n",
    "    description = 'Tax Withholding Verification'\n",
    "elif ml_service == 'PAD':\n",
    "    algorithm = 'Isolation_Forest'\n",
    "    description = 'Payroll Anomaly detection'\n",
    "else:\n",
    "    algorithm = 'Other algorithm'\n",
    "    description = 'Other'\n",
    "    \n",
    "tags = {'RunNumber':run_num,'RunId':dets['runId'],'Model':metrics['Model Name'],'ModelVersion':model_version,'TrainSetSize':metrics['num train examples'],'Algorithm':algorithm,'AlgorithmType':metrics['algorithm']}\n",
    "\n",
    "if algorithm == 'Isolation_Forest':\n",
    "    tags['ISONumEstimators'] = metrics['iso num estimators']\n",
    "    tags['ISOMaxSamples'] = metrics['iso max samples']\n",
    "    tags['ISOMaxFeatures'] = metrics['iso max features']\n",
    "else:\n",
    "    tags['HiddenLayers'] = metrics['num hidden layers']\n",
    "    tags['LearningRate'] = metrics['learning rate']\n",
    "    tags['Iters'] = metrics['iters']         \n",
    "\n",
    "model_config = MLModelConfig.get_model_config_from_web_service_for_model(ml_service,model)\n",
    "\n",
    "if model_config:\n",
    "    cat_feats = len(model_config.get_feature_field_names_with_type('C'))\n",
    "    num_feats = len(model_config.get_feature_field_names_with_type('N'))\n",
    "    tags['NumFeatures'] = cat_feats + num_feats\n",
    "else:\n",
    "    tags['NumFeatures'] = 0\n",
    "tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TWV_model_SS01_011\tTWV_model_SS01_011:1\t1\n"
     ]
    }
   ],
   "source": [
    "# register model \n",
    "\n",
    "azure_model_name = ml_service + '_model_' + model + '_' + model_version\n",
    "\n",
    "reg_model = run.register_model(model_name=azure_model_name, model_path='outputs/' + ml_service + '_model_' + model + '_' + model_version + '.pkl',tags=tags) #, description = description)\n",
    "print(reg_model.name, reg_model.id, reg_model.version, sep='\\t')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
